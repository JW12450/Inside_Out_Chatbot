{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"joy_chatbot.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"feYVZ0lvPF4b","outputId":"079779e6-bb36-4038-d344-cb501d5d18de"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ArzbmuUTQfuJ"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","import urllib.request\n","import time\n","import tensorflow_datasets as tfds\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z37NZLx11Dqn"},"source":["# 1) 데이터 로드"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"VQPqnqxQSN-1","outputId":"88f81616-98f4-437e-ac7b-d0d69ad6311c"},"source":["train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/joydata3.csv',usecols=['Q','A','label'])\n","train_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>아..</td>\n","      <td>오히려 좋아</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>너어? 나한테 맡긴 기타, 니네 아빠한테 확 말한다?</td>\n","      <td>어떻게든 되겠지 뭐 ~</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>네.</td>\n","      <td>인생은 아름다운거야</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>연애 위기인 거 같아</td>\n","      <td>좋은 일이 생길거야!</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>결국 또 제 자리군요.</td>\n","      <td>긍정적으로 생각하자</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6445</th>\n","      <td>학교 다니면서 힘들 때도 많았지만 제가 꿈 꿨던 일이라 정말 열심히 공부했어요.</td>\n","      <td>그 좋은 결과만큼 앞으로 당신의 미래도 기쁘고 즐겁길 바랍니다.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6446</th>\n","      <td>그래서 혼자 잘 다독이고 의연하게 지내려고 노력했어요.</td>\n","      <td>충분히 잘 하고 계시답니다. 차근히 조금씩 노력해봐요.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6447</th>\n","      <td>그냥 집에서 푹 쉬면 되겠지 싶어서 그날은 집에 일찍 들어가서 쉬었지.</td>\n","      <td>충분한 휴식은 일상의 활력이 된답니다.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6448</th>\n","      <td>너무 힘든 날은 하루종일 집에서 쉬었어.</td>\n","      <td>다음 단계로 가기 위한 휴식도 반드시 필요한 과정이랍니다.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6449</th>\n","      <td>힘들면 잠시 앉아서 쉬면 낫더라고..</td>\n","      <td>조금 쉬면 분명 나아질 거예요.</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6450 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                 Q  ... label\n","0                                              아..  ...     2\n","1                    너어? 나한테 맡긴 기타, 니네 아빠한테 확 말한다?  ...     2\n","2                                               네.  ...     2\n","3                                      연애 위기인 거 같아  ...     2\n","4                                     결국 또 제 자리군요.  ...     2\n","...                                            ...  ...   ...\n","6445  학교 다니면서 힘들 때도 많았지만 제가 꿈 꿨던 일이라 정말 열심히 공부했어요.  ...     2\n","6446                그래서 혼자 잘 다독이고 의연하게 지내려고 노력했어요.  ...     2\n","6447       그냥 집에서 푹 쉬면 되겠지 싶어서 그날은 집에 일찍 들어가서 쉬었지.  ...     2\n","6448                        너무 힘든 날은 하루종일 집에서 쉬었어.  ...     2\n","6449                          힘들면 잠시 앉아서 쉬면 낫더라고..  ...     2\n","\n","[6450 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"5h4a-t5VQolD"},"source":["questions = []\n","for sentence in train_data['Q']:\n","    # 구두점에 대해서 띄어쓰기\n","    # ex) 12시 땡! -> 12시 땡 !\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","    sentence = sentence.strip()\n","    \n","    questions.append(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3H4pLRWQonQ"},"source":["answers = []\n","for sentence in train_data['A']:\n","    # 구두점에 대해서 띄어쓰기\n","    # ex) 12시 땡! -> 12시 땡 !\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","    sentence = sentence.strip()\n","    answers.append(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLGKh1hBQop9","outputId":"07ef4553-3dfd-42ef-ed42-06f1d74079af"},"source":["print(questions[:5])\n","print(answers[:5])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['아 .  .', '너어 ?  나한테 맡긴 기타 ,  니네 아빠한테 확 말한다 ?', '네 .', '연애 위기인 거 같아', '결국 또 제 자리군요 .']\n","['오히려 좋아', '어떻게든 되겠지 뭐 ~', '인생은 아름다운거야', '좋은 일이 생길거야 !', '긍정적으로 생각하자']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gIBiYeDFQosW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uzG43911Jbe"},"source":["# 2) 단어 집합 생성\n","\n","subwordtokenizer 이용"]},{"cell_type":"code","metadata":{"id":"c0JgOS74QovJ"},"source":["tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    questions + answers, target_vocab_size=2**13)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4_u5o2I1I1b"},"source":["# 시작 토큰과 종료 토큰에 대한 정수 부여.\n","START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n","VOCAB_SIZE = tokenizer.vocab_size + 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"foV3Ic-jQoxm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b6b37e1-ae14-4cc2-d71f-a91a287e9711"},"source":["print('시작 토큰 번호 :',START_TOKEN)\n","print('종료 토큰 번호 :',END_TOKEN)\n","print('단어 집합의 크기 :',VOCAB_SIZE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["시작 토큰 번호 : [7415]\n","종료 토큰 번호 : [7416]\n","단어 집합의 크기 : 7417\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VomA438xQo2C"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aSZoYPmo2gnN"},"source":["# 3) 정수인코딩, 패딩"]},{"cell_type":"code","metadata":{"id":"BJ3uIrZzQo5C","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9efc63c-5a98-43a6-cf8a-c9676d115bc0"},"source":["# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n","print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[210])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["임의의 질문 샘플을 정수 인코딩 : [2667, 6862, 1756, 64, 9, 3095, 3, 5544, 3512, 2399, 1522, 3, 7395, 7334, 7326, 7395, 7334, 7307, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KyHqRjuGQo7u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a377b0c-0eb0-4b55-c6d9-8b0ca9c5ebc2"},"source":["# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n","# 임의의 입력 문장을 sample_string에 저장\n","sample_string = questions[210]\n","\n","# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n","tokenized_string = tokenizer.encode(sample_string)\n","print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n","\n","# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n","original_string = tokenizer.decode(tokenized_string)\n","print ('기존 문장: {}'.format(original_string))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["정수 인코딩 후의 문장 [2667, 6862, 1756, 64, 9, 3095, 3, 5544, 3512, 2399, 1522, 3, 7395, 7334, 7326, 7395, 7334, 7307, 1]\n","기존 문장: 일부러 꿔준다고도 하잖아 .  이자받아 먹으려고 .  쯧쯔 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fu8TaoarQo_I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"88ea7c41-9f61-4a40-d4d0-37ff5137515c"},"source":["for ts in tokenized_string:\n","  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2667 ----> 일부러 \n","6862 ----> 꿔\n","1756 ----> 준다\n","64 ----> 고\n","9 ----> 도 \n","3095 ----> 하잖아\n","3 ---->  .  \n","5544 ----> 이자\n","3512 ----> 받아 \n","2399 ----> 먹으\n","1522 ----> 려고\n","3 ---->  .  \n","7395 ----> �\n","7334 ----> �\n","7326 ----> �\n","7395 ----> �\n","7334 ----> �\n","7307 ----> �\n","1 ---->  .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PyLEVOwoQpBv"},"source":["# 최대 길이를 40으로 정의\n","MAX_LENGTH = 40\n","\n","# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","\n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n","    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n","    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n","\n","    tokenized_inputs.append(sentence1)\n","    tokenized_outputs.append(sentence2)\n","\n","  # 패딩\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n","\n","  return tokenized_inputs, tokenized_outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMp4o07tQpEa"},"source":["questions, answers = tokenize_and_filter(questions, answers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCBUpmO4Qn_F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0cd3a41c-4f3a-4cd0-c8de-5c025386dc46"},"source":["print('질문 데이터의 크기(shape) :', questions.shape)\n","print('답변 데이터의 크기(shape) :', answers.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["질문 데이터의 크기(shape) : (6450, 40)\n","답변 데이터의 크기(shape) : (6450, 40)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pKEDMPVgQoBq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"49859e91-3e5d-4148-ba41-5f89a12c7cfc"},"source":["# 0번 샘플을 임의로 출력\n","print(questions[210])\n","print(answers[210])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[7415 2667 6862 1756   64    9 3095    3 5544 3512 2399 1522    3 7395\n"," 7334 7326 7395 7334 7307    1 7416    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0]\n","[7415  101    8  632  730 7416    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"phdLJozVQoD4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0e3b21eh3U5D"},"source":["# 4) 인코더, 디코더의 입력, 레이블 생성"]},{"cell_type":"code","metadata":{"id":"wY3PDKxX3Iph"},"source":["# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n","# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 20000\n","\n","# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n","dataset = tf.data.Dataset.from_tensor_slices((    # tf.data.Dataset을 사용하여 데이터를 배치 단위로 로드\n","    {\n","        'inputs': questions,\n","        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n","    },\n","    {\n","        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdUQFm4J3IsE","outputId":"12cbcf8d-1e32-4775-aa02-0083d4704976"},"source":["# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n","print(answers[0]) # 기존 샘플\n","print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n","print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["[7415  261   39 7416    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0]\n","[[7415  261   39 7416    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]]\n","[[ 261   39 7416    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qrAR_J__3of6"},"source":["# 5) 트랜스포머 모델 구현"]},{"cell_type":"code","metadata":{"id":"P1FpVa8c4eCP"},"source":["class PositionalEncoding(tf.keras.layers.Layer):\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)\n","\n","    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","\n","    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    angle_rads = np.zeros(angle_rads.shape)\n","    angle_rads[:, 0::2] = sines\n","    angle_rads[:, 1::2] = cosines\n","    pos_encoding = tf.constant(angle_rads)\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","\n","    print(pos_encoding.shape)\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n","\n","  def get_config(self):\n","    config = super().get_config().copy()\n","    config.update({\n","        'pos_encoding' : self.pos_encoding,\n","    })\n","    return config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EE_eWKw14jpI"},"source":["def scaled_dot_product_attention(query, key, value, mask):\n","  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n","\n","  # Q와 K의 곱. 어텐션 스코어 행렬.\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # 스케일링\n","  # dk의 루트값으로 나눠준다.\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n","  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n","  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  output = tf.matmul(attention_weights, value)\n","\n","  return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEURSH8i4nTN"},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    # d_model을 num_heads로 나눈 값.\n","    # 논문 기준 : 64\n","    self.depth = d_model // self.num_heads\n","\n","    # WQ, WK, WV에 해당하는 밀집층 정의\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    # WO에 해당하는 밀집층 정의\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  def get_config(self):\n","    config = super().get_config().copy()\n","    config.update({\n","        'num_heads' : self.num_heads,\n","        'd_model' : self.d_model,\n","        'depth' : self.depth,\n","        'query_dense' : self.query_dense,\n","        'key_dense' : self.key_dense,\n","        'value_dense' : self.value_dense,\n","        'dense' : self.dense,\n","    })\n","    return config\n","\n","  # num_heads 개수만큼 q, k, v를 split하는 함수\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n","    # q : (batch_size, query의 문장 길이, d_model)\n","    # k : (batch_size, key의 문장 길이, d_model)\n","    # v : (batch_size, value의 문장 길이, d_model)\n","    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # 2. 헤드 나누기\n","    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n","    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n","    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # 4. 헤드 연결(concatenate)하기\n","    # (batch_size, query의 문장 길이, d_model)\n","    concat_attention = tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model))\n","\n","    # 5. WO에 해당하는 밀집층 지나기\n","    # (batch_size, query의 문장 길이, d_model)\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qs_gNMKM4C8y"},"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, key의 문장 길이)\n","  return mask[:, tf.newaxis, tf.newaxis, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOAdyBZx4C_g"},"source":["def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': padding_mask # 패딩 마스크 사용\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWIW-5Zy4w86"},"source":["def encoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 인코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkOKHlv241Gj"},"source":["def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n","  return tf.maximum(look_ahead_mask, padding_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cExxPB1642cB"},"source":["def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","\n","  # 룩어헤드 마스크(첫번째 서브층)\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","\n","  # 패딩 마스크(두번째 서브층)\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': look_ahead_mask # 룩어헤드 마스크\n","      })\n","\n","  # 잔차 연결과 층 정규화\n","  attention1 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention1 + inputs)\n","\n","  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n","          'mask': padding_mask # 패딩 마스크\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention2 + attention1)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(outputs + attention2)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_W33047Y45wv"},"source":["def decoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","\n","  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 디코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gm99GzwF3xOy"},"source":["def transformer(vocab_size, num_layers, dff,\n","                d_model, num_heads, dropout,\n","                name=\"transformer\"):\n","\n","  # 인코더의 입력\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 디코더의 입력\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  # 인코더의 패딩 마스크\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","\n","  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask, output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","\n","  # 디코더의 패딩 마스크(두번째 서브층)\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n","  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n","\n","  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n","  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  # 다음 단어 예측을 위한 출력층\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUJeGC6d3Iw_","outputId":"2b6e72b3-ec7b-4c62-8fed-dfa4125afcd6"},"source":["tf.keras.backend.clear_session()\n","\n","# Hyper-parameters\n","D_MODEL = 256\n","NUM_LAYERS = 2\n","NUM_HEADS = 8\n","DFF = 512\n","DROPOUT = 0.1\n","model = transformer(\n","    vocab_size=VOCAB_SIZE,\n","    num_layers=NUM_LAYERS,\n","    dff=DFF,\n","    d_model=D_MODEL,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 7417, 256)\n","(1, 7417, 256)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V1FV5mcW5Req"},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def get_config(self):\n","    config = {\n","    'd_model': self.d_model,\n","    'warmup_steps': self.warmup_steps,\n","\n","     }\n","    return config\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"domiYFps5Ufj"},"source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8MHBOUO3IzN"},"source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AOfVXuZT5eW7"},"source":["# 6) 챗봇 모델"]},{"cell_type":"code","metadata":{"id":"UsWvBYyo3YXj"},"source":["def evaluate(sentence):\n","  sentence = preprocess_sentence(sentence)\n","\n","  sentence = tf.expand_dims(\n","      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n","\n","  output = tf.expand_dims(START_TOKEN, 0)\n","\n","  # 디코더의 예측 시작\n","  for i in range(MAX_LENGTH):\n","    predictions = model(inputs=[sentence, output], training=False)\n","\n","    # 현재(마지막) 시점의 예측 단어를 받아온다.\n","    predictions = predictions[:, -1:, :]\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n","    if tf.equal(predicted_id, END_TOKEN[0]):\n","      break\n","\n","    # 마지막 시점의 예측 단어를 출력에 연결\n","    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOcE3XTt3YZ2"},"source":["def predict(sentence):\n","  prediction = evaluate(sentence)\n","\n","  predicted_sentence = tokenizer.decode(\n","      [i for i in prediction if i < tokenizer.vocab_size])\n","\n","  print('Input: {}'.format(sentence))\n","  print('Output: {}'.format(predicted_sentence))\n","\n","  return predicted_sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TfEayITg3YcV"},"source":["def preprocess_sentence(sentence):\n","  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","  sentence = sentence.strip()\n","  return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4MIMHYNRI_U"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2-ZaL3kRgqM","outputId":"23f78850-9009-448b-da09-1596d386e44e"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","inputs (InputLayer)             [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","dec_inputs (InputLayer)         [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n","__________________________________________________________________________________________________\n","encoder (Functional)            (None, None, 256)    2952960     inputs[0][0]                     \n","                                                                 enc_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n","__________________________________________________________________________________________________\n","dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n","__________________________________________________________________________________________________\n","decoder (Functional)            (None, None, 256)    3480320     dec_inputs[0][0]                 \n","                                                                 encoder[0][0]                    \n","                                                                 look_ahead_mask[0][0]            \n","                                                                 dec_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","outputs (Dense)                 (None, None, 7417)   1906169     decoder[0][0]                    \n","==================================================================================================\n","Total params: 8,339,449\n","Trainable params: 8,339,449\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gOaYbiTzRrYd"},"source":["checkpoint_path = \"/content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\" # you should change this checkpoint name\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# 모델의 가중치를 저장하는 콜백 만들기\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91U3xUSkRCP3"},"source":["model.save_weights(checkpoint_path.format(epoch=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prlePx9qRzoA","outputId":"b2e55dc9-2db6-4335-a438-5e19ddb4cbaa"},"source":["EPOCHS = 30\n","model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","101/101 [==============================] - 17s 80ms/step - loss: 1.6482 - accuracy: 0.0145\n","\n","Epoch 00001: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 2/30\n","101/101 [==============================] - 8s 78ms/step - loss: 1.5078 - accuracy: 0.0256\n","\n","Epoch 00002: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 3/30\n","101/101 [==============================] - 8s 81ms/step - loss: 1.3647 - accuracy: 0.0264\n","\n","Epoch 00003: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 4/30\n","101/101 [==============================] - 8s 79ms/step - loss: 1.2331 - accuracy: 0.0388\n","\n","Epoch 00004: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 5/30\n","101/101 [==============================] - 8s 81ms/step - loss: 1.1459 - accuracy: 0.0409\n","\n","Epoch 00005: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 6/30\n","101/101 [==============================] - 8s 79ms/step - loss: 1.0633 - accuracy: 0.0446\n","\n","Epoch 00006: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 7/30\n","101/101 [==============================] - 8s 80ms/step - loss: 0.9860 - accuracy: 0.0552\n","\n","Epoch 00007: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 8/30\n","101/101 [==============================] - 8s 80ms/step - loss: 0.9109 - accuracy: 0.0657\n","\n","Epoch 00008: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 9/30\n","101/101 [==============================] - 8s 81ms/step - loss: 0.8394 - accuracy: 0.0719\n","\n","Epoch 00009: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 10/30\n","101/101 [==============================] - 8s 78ms/step - loss: 0.7777 - accuracy: 0.0765\n","\n","Epoch 00010: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 11/30\n","101/101 [==============================] - 8s 82ms/step - loss: 0.7236 - accuracy: 0.0811\n","\n","Epoch 00011: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 12/30\n","101/101 [==============================] - 8s 79ms/step - loss: 0.6735 - accuracy: 0.0860\n","\n","Epoch 00012: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 13/30\n","101/101 [==============================] - 8s 83ms/step - loss: 0.6217 - accuracy: 0.0919\n","\n","Epoch 00013: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 14/30\n","101/101 [==============================] - 8s 84ms/step - loss: 0.5690 - accuracy: 0.0981\n","\n","Epoch 00014: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 15/30\n","101/101 [==============================] - 8s 82ms/step - loss: 0.5148 - accuracy: 0.1056\n","\n","Epoch 00015: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 16/30\n","101/101 [==============================] - 8s 80ms/step - loss: 0.4593 - accuracy: 0.1138\n","\n","Epoch 00016: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 17/30\n","101/101 [==============================] - 8s 80ms/step - loss: 0.4011 - accuracy: 0.1226\n","\n","Epoch 00017: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 18/30\n","101/101 [==============================] - 8s 81ms/step - loss: 0.3447 - accuracy: 0.1321\n","\n","Epoch 00018: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 19/30\n","101/101 [==============================] - 8s 79ms/step - loss: 0.2880 - accuracy: 0.1418\n","\n","Epoch 00019: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 20/30\n","101/101 [==============================] - 8s 80ms/step - loss: 0.2336 - accuracy: 0.1514\n","\n","Epoch 00020: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 21/30\n","101/101 [==============================] - 8s 80ms/step - loss: 0.1835 - accuracy: 0.1605\n","\n","Epoch 00021: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 22/30\n","101/101 [==============================] - 8s 80ms/step - loss: 0.1415 - accuracy: 0.1684\n","\n","Epoch 00022: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 23/30\n","101/101 [==============================] - 8s 79ms/step - loss: 0.1062 - accuracy: 0.1738\n","\n","Epoch 00023: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 24/30\n","101/101 [==============================] - 8s 79ms/step - loss: 0.0777 - accuracy: 0.1783\n","\n","Epoch 00024: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 25/30\n","101/101 [==============================] - 8s 81ms/step - loss: 0.0580 - accuracy: 0.1810\n","\n","Epoch 00025: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 26/30\n","101/101 [==============================] - 8s 81ms/step - loss: 0.0457 - accuracy: 0.1822\n","\n","Epoch 00026: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 27/30\n","101/101 [==============================] - 8s 81ms/step - loss: 0.0372 - accuracy: 0.1831\n","\n","Epoch 00027: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 28/30\n","101/101 [==============================] - 8s 81ms/step - loss: 0.0328 - accuracy: 0.1836\n","\n","Epoch 00028: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 29/30\n","101/101 [==============================] - 8s 81ms/step - loss: 0.0300 - accuracy: 0.1835\n","\n","Epoch 00029: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n","Epoch 30/30\n","101/101 [==============================] - 8s 79ms/step - loss: 0.0278 - accuracy: 0.1840\n","\n","Epoch 00030: saving model to /content/drive/MyDrive/인사이드아웃 챗봇/chatbot/load_model/joy/cp.ckpt\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa23005aa10>"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itzB-fNUSOiL","outputId":"84754132-1693-4c3b-97be-7acb30502e01"},"source":["# 가중치 로드\n","model.load_weights(checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbccc7bfb50>"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DRUkGA83YeX","outputId":"0e1d2f0e-0f6c-4f22-99aa-334f09cc1106"},"source":["output = predict(\"안녕\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 안녕\n","Output: 안녕하세요 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDiFXDDK3I4G","outputId":"8839fe28-2fb7-4955-cd58-54bc88bcd5bf"},"source":["output = predict(\"오늘 족발 맛있었어 배불러\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 오늘 족발 맛있었어 배불러\n","Output: 로맨틱한 남편이네요 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bK3uTbJV3I6S","outputId":"3a8885bc-8e31-4e36-e98d-1c5947a68a9e"},"source":["output = predict(\"퇴사하고 싶다...\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 퇴사하고 싶다...\n","Output: 난 뭐든 좋아 !  !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y10IzCI47wiN","outputId":"6849a64c-ce38-4a37-c40a-a9003ac26445"},"source":["output = predict(\"친구랑 싸웠어 짜증나\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 친구랑 싸웠어 짜증나\n","Output: 그쪽에 비하면 애들 장난 수준이죠 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zerf1oYQuVWj","outputId":"e82eeab4-bd13-431a-8ef0-2768f61635d1"},"source":["output = predict(\"아 진짜 어떻게 해야할지를 모르겠네\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 아 진짜 어떻게 해야할지를 모르겠네\n","Output: 난 뭐든 좋아 !  !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B4o3loa_uESU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6cf8941-f6d0-4014-ed57-ddea41c2a3a5"},"source":["output = predict(\"사랑해\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 사랑해\n","Output: 하늘 만큼 땅 만큼 사랑해요 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DzM9uvKN1q80","colab":{"base_uri":"https://localhost:8080/"},"outputId":"376f8350-b25e-4a80-8c81-c22dc24d49a8"},"source":["output = predict(\"사랑한다고\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 사랑한다고\n","Output: 곧 폐회식이 시작될 테니 돌아가 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H7PzMAhS8f47","colab":{"base_uri":"https://localhost:8080/"},"outputId":"896d33af-1547-4c03-abd6-2f50f30a51fa"},"source":["output = predict(\"너 이름이 뭐야?\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 너 이름이 뭐야?\n","Output: 하필 같은 이름이라니 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dfmkIXOs6qWX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"874ac347-2bc5-497e-abcd-0a94c7221304"},"source":["output = predict(\"날씨가 좀 덥다\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 날씨가 좀 덥다\n","Output: 하지만 난 행복해\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jU1HlhOu9NXg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14d1690c-609b-4e58-8bac-bfaffa2f8a78"},"source":["output = predict(\"시끄럽다고??\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 시끄럽다고??\n","Output: 너무 기대되서 잠이 안오는걸 ? ㅎㅎ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zZjbGpi8vVO","outputId":"746811a8-a1f7-4817-fd50-95e82e52ab42"},"source":["output = predict(\"이거 얼마에요?\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 이거 얼마에요?\n","Output: 어 ?  예쁘다\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrniNdx88yKx","outputId":"218698d9-cbcb-4c5f-a95b-6bdea224f32a"},"source":["output = predict(\"나 진짜 외롭다\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 나 진짜 외롭다\n","Output: 아름다운 세상이야 정말\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0q0NpDl80uj","outputId":"6b2cac0d-7891-4c60-d075-c5353b3cc470"},"source":["output = predict(\"내일 같이 놀러갈래?\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 내일 같이 놀러갈래?\n","Output: 연인과 함께면 어디든 좋아요 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXGfTOBk9I2E","outputId":"0d02aa91-2639-402f-8cac-1ca0388f1033"},"source":["output = predict(\"오늘 기분 어때?\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 오늘 기분 어때?\n","Output: 사랑에 국경은 없어요 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8fmRO2vDVan","outputId":"62d72ba6-b043-4985-95cf-9b8210735cd4"},"source":["output = predict(\"난 기분 좋은데 너는 어때?\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 난 기분 좋은데 너는 어때?\n","Output: 애절한 이야기입니다 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MUGCF0OkPih7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e9b82ca-5701-4016-a6da-c447b9f8e0e0"},"source":["output = predict(\"이 영화 진짜 슬프다\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 이 영화 진짜 슬프다\n","Output: 무단이탈은 연대책임이다 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wiK-GS9S9Ncq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee2b88b7-c618-4269-c1fe-25c20594e9ce"},"source":["output = predict(\"남자친구와 헤어지고 싶어\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: 남자친구와 헤어지고 싶어\n","Output: 썸 정도는 괜찮아요 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bQZPOk-R9W7b"},"source":[""],"execution_count":null,"outputs":[]}]}